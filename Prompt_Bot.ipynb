{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xr7bl8RtNYJ"
   },
   "source": [
    "### Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2802,
     "status": "ok",
     "timestamp": 1730651990622,
     "user": {
      "displayName": "Nuttapong Wongchai",
      "userId": "08431007192556473855"
     },
     "user_tz": -420
    },
    "id": "A7W9Zkkhs_60",
    "outputId": "3d898428-cbb7-4bbe-b0e8-21a17bcf8d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgqRao_mtc7H"
   },
   "source": [
    "### Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8742,
     "status": "ok",
     "timestamp": 1730652052462,
     "user": {
      "displayName": "Nuttapong Wongchai",
      "userId": "08431007192556473855"
     },
     "user_tz": -420
    },
    "id": "jfx0dDPjthqM",
    "outputId": "0dc058f3-34a9-43ce-f7d2-67a52e05d302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/peft.git\n",
      "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-rf17azu8\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-rf17azu8\n",
      "  Resolved https://github.com/huggingface/peft.git to commit b5b902368d2a7f349783a96d9d3c686ea0ca3a05\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.4.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
      "Requirement already satisfied: loralib in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
      "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
      "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.46.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.4)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.4.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.4.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.10)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart==0.0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.12)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.7.2)\n",
      "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.2)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (12.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.16.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (4.66.6)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.2.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.13.3.dev0) (2.5.0+cu121)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire) (2.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.13.3.dev0) (3.4.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.13.3.dev0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.13.3.dev0) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[sentencepiece] git+https://github.com/huggingface/peft.git accelerate bitsandbytes loralib fire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYPVh9-BEQOk"
   },
   "source": [
    "###Class Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_Io4KUzEUaX"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import traceback\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "class Stream(transformers.StoppingCriteria):\n",
    "    def __init__(self, callback_func=None):\n",
    "        self.callback_func = callback_func\n",
    "\n",
    "    def __call__(self, input_ids, scores) -> bool:\n",
    "        if self.callback_func is not None:\n",
    "            self.callback_func(input_ids[0])\n",
    "        return False\n",
    "\n",
    "class Iteratorize:\n",
    "    \"\"\"\n",
    "    Transforms a function that takes a callback\n",
    "    into a lazy iterator (generator).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, func, kwargs={}, callback=None):\n",
    "        self.mfunc = func\n",
    "        self.c_callback = callback\n",
    "        self.q = Queue()\n",
    "        self.sentinel = object()\n",
    "        self.kwargs = kwargs\n",
    "        self.stop_now = False\n",
    "\n",
    "        def _callback(val):\n",
    "            if self.stop_now:\n",
    "                raise ValueError\n",
    "            self.q.put(val)\n",
    "\n",
    "        def gentask():\n",
    "            try:\n",
    "                ret = self.mfunc(callback=_callback, **self.kwargs)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "                pass\n",
    "\n",
    "            self.q.put(self.sentinel)\n",
    "            if self.c_callback:\n",
    "                self.c_callback(ret)\n",
    "\n",
    "        self.thread = Thread(target=gentask)\n",
    "        self.thread.start()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        obj = self.q.get(True, None)\n",
    "        if obj is self.sentinel:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.stop_now = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1gNWBAREjww"
   },
   "source": [
    "###Class Promter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YcAcNLdfEnQs"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path as osp\n",
    "from typing import Union\n",
    "\n",
    "class Prompter:\n",
    "    __slots__ = (\"template\", \"_verbose\")\n",
    "\n",
    "    def __init__(self, template_name: str = \"\", verbose: bool = False):\n",
    "        self._verbose = verbose\n",
    "        template_name = \"alpaca\"\n",
    "        self.template = {\n",
    "            \"description\": \"Template used by Alpaca-LoRA.\",\n",
    "            \"prompt_input\": \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\",\n",
    "            \"prompt_no_input\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\\n\",\n",
    "            \"response_split\": \"### Response:\"\n",
    "        }\n",
    "        if self._verbose:\n",
    "            print(f\"Using prompt template {template_name}: {self.template['description']}\")\n",
    "\n",
    "    def generate_prompt(self, instruction: str, input: Union[None, str] = None) -> str:\n",
    "        if input:\n",
    "            res = self.template[\"prompt_input\"].format(instruction=instruction, input=input)\n",
    "        else:\n",
    "            res = self.template[\"prompt_no_input\"].format(instruction=instruction)\n",
    "        if self._verbose:\n",
    "            print(res)\n",
    "        return res\n",
    "\n",
    "    def get_response(self, output: str) -> str:\n",
    "        return output.split(self.template[\"response_split\"])[1].strip()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "try:\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = \"mps\"\n",
    "except:  # noqa: E722\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znKjXU06vL5G"
   },
   "source": [
    "### Load Base Model and Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "eb6a865a8fd94ff2982a2d2533d3d9c8",
      "7ebc6e54f29b4a5d9aa4760b4bcd0e59",
      "32c94d50cb2442068e753b205c17217e",
      "00e977416cd945e980b3be1388e94010",
      "b718655efcad480597c3406a54f40c22",
      "d7e34248246c4ad2b937d1474c2081a7",
      "d5613836f4614bceb3f409b33dd3d0ae",
      "cb5b55dbcd4c4e7cb6c602400663f325",
      "f18a6478826d43bc87ae379713baa239",
      "d9b8ec7bd020478a80d98d40b2bc9bdb",
      "ce92c34bc3624e58a32109f9b3f06c4f"
     ]
    },
    "executionInfo": {
     "elapsed": 16357,
     "status": "ok",
     "timestamp": 1730652994014,
     "user": {
      "displayName": "Nuttapong Wongchai",
      "userId": "08431007192556473855"
     },
     "user_tz": -420
    },
    "id": "5MbdJXfXvRVF",
    "outputId": "69723121-c991-4414-c3c9-437937137838"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6a865a8fd94ff2982a2d2533d3d9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import GenerationConfig, LlamaForCausalLM, LlamaTokenizer\n",
    "from peft import PeftModel, LoraConfig\n",
    "\n",
    "base_model = '/content/drive/MyDrive/BaseModel/openthaigpt-1.0.0-7b-chat'\n",
    "lora_weight = '/content/drive/MyDrive/TrainModel/Com_Laws'\n",
    "\n",
    "adapter_config = LoraConfig(\n",
    "    peft_type=\"LORA\",\n",
    "    base_model_name_or_path=base_model,\n",
    "    inference_mode=True,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"v_proj\", \"q_proj\"]\n",
    ")\n",
    "\n",
    "lora_8bit = True\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(base_model)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if device == \"cuda\":\n",
    "    model = LlamaForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        load_in_8bit=lora_8bit,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    model = PeftModel.from_pretrained(\n",
    "        model,\n",
    "        lora_weight,\n",
    "        config=adapter_config,\n",
    "        torch_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "elif device == \"cpu\":\n",
    "    model = LlamaForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        device_map={\"\": device},\n",
    "        torch_dtype=torch.float16\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(\n",
    "        model,\n",
    "        lora_weight,\n",
    "        config=adapter_config,\n",
    "        torch_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id = 2\n",
    "model.config.bos_token_id = 1\n",
    "model.config.eos_token_id = 2\n",
    "\n",
    "if not lora_8bit:\n",
    "    model.half()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "    model = torch.compile(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mW7JPHYr8YF-"
   },
   "source": [
    "###Evaluate by calling a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhP_OqE68eSP"
   },
   "outputs": [],
   "source": [
    "def text_evaluate(\n",
    "    instruction,\n",
    "    input=None,\n",
    "    num_beams=4,\n",
    "    repetition_penalty=2,\n",
    "    no_repeat_ngram_size=5,\n",
    "    max_new_tokens=128,\n",
    "    stream_output=True,\n",
    "    **kwargs,\n",
    "):\n",
    "    prompter = Prompter(verbose=True)\n",
    "    prompt = prompter.generate_prompt(instruction, input)\n",
    "    inputs = tokenizer(prompt, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token_id = 0\n",
    "\n",
    "    generation_config = GenerationConfig(\n",
    "        num_beams=num_beams,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    generate_params = {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"generation_config\": generation_config,\n",
    "        \"return_dict_in_generate\": True,\n",
    "        \"output_scores\": True,\n",
    "        \"max_new_tokens\": max_new_tokens,\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generation_output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            generation_config=generation_config,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "        )\n",
    "    s = generation_output.sequences[0]\n",
    "    return tokenizer.decode(s, skip_special_tokens=True).split(\"### Response:\")[1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bSdsVYh9ut-"
   },
   "source": [
    "###Prompt input Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30987,
     "status": "ok",
     "timestamp": 1730653678740,
     "user": {
      "displayName": "Nuttapong Wongchai",
      "userId": "08431007192556473855"
     },
     "user_tz": -420
    },
    "id": "C3l0rFUK9xyj",
    "outputId": "266a88d9-2801-41fe-d42c-e4260d47eb9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question :  นาย A ทำงานให้กับธนาคารและล่วงรู้มาตรการรักษาความปลอดภัยในการเข้าถึงระบบคอมพิวเตอร์ของธนาคาร เขานำข้อมูลวิธีการเข้าถึงระบบนี้ไปเผยแพร่ในเว็บไซต์ออนไลน์ ทำให้แฮกเกอร์สามารถนำข้อมูลนี้ไปใช้ก่ออาชญากรรมผิดกฎหมายไหม และจะรับโทษอะไร\n",
      "Using prompt template alpaca: Template used by Alpaca-LoRA.\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "นาย A ทำงานให้กับธนาคารและล่วงรู้มาตรการรักษาความปลอดภัยในการเข้าถึงระบบคอมพิวเตอร์ของธนาคาร เขานำข้อมูลวิธีการเข้าถึงระบบนี้ไปเผยแพร่ในเว็บไซต์ออนไลน์ ทำให้แฮกเกอร์สามารถนำข้อมูลนี้ไปใช้ก่ออาชญากรรมผิดกฎหมายไหม และจะรับโทษอะไร\n",
      "\n",
      "### Response:\n",
      "\n",
      "Answer :  นาย A อาจต้องรับโทษจำคุก 5 ปี และปรับเงิน 100,000 บาท หากเขาถูกตัดสินว่ามีความผิดฐานเผยแพร่มาตรการรักษาความปลอดภัยในการเข้าถึงระบบคอมพิวเตอร์ของธนาคารโดยผิดกฎหมาย เนื่องจากการกระทำดังกล่าวเป็นอันตรายต่อธนาคารและผู้ใช้บริการของธนาคาร นอกจากนี้ นาย A อาจต้องรับโทษจำคุก 5 ปี และปรับเงิน 100,000 บาท หากเขาถูกตัดสินว่ามีความผิดฐานเผยแพร่มาตรการรักษาความปลอดภัยในการเข้าถึงระบบคอมพิวเตอร์ของธนาคารโดยผิดกฎหมาย เนื่องจากการกระทำดังกล่าวเป็นอันตรายต่อธนาคารและผู้ใช้บริการของธนาคาร นอกจากนี้\n"
     ]
    }
   ],
   "source": [
    "question = 'นาย A ทำงานให้กับธนาคารและล่วงรู้มาตรการรักษาความปลอดภัยในการเข้าถึงระบบคอมพิวเตอร์ของธนาคาร เขานำข้อมูลวิธีการเข้าถึงระบบนี้ไปเผยแพร่ในเว็บไซต์ออนไลน์ ทำให้แฮกเกอร์สามารถนำข้อมูลนี้ไปใช้ก่ออาชญากรรมผิดกฎหมายไหม และจะรับโทษอะไร'\n",
    "\n",
    "print(\"Question : \", question)\n",
    "print(\"Answer : \", text_evaluate(question))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNhIrtplm8kGzF3ZYhY7MT+",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00e977416cd945e980b3be1388e94010": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9b8ec7bd020478a80d98d40b2bc9bdb",
      "placeholder": "​",
      "style": "IPY_MODEL_ce92c34bc3624e58a32109f9b3f06c4f",
      "value": " 3/3 [00:12&lt;00:00,  4.09s/it]"
     }
    },
    "32c94d50cb2442068e753b205c17217e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb5b55dbcd4c4e7cb6c602400663f325",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f18a6478826d43bc87ae379713baa239",
      "value": 3
     }
    },
    "7ebc6e54f29b4a5d9aa4760b4bcd0e59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7e34248246c4ad2b937d1474c2081a7",
      "placeholder": "​",
      "style": "IPY_MODEL_d5613836f4614bceb3f409b33dd3d0ae",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "b718655efcad480597c3406a54f40c22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb5b55dbcd4c4e7cb6c602400663f325": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce92c34bc3624e58a32109f9b3f06c4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5613836f4614bceb3f409b33dd3d0ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7e34248246c4ad2b937d1474c2081a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9b8ec7bd020478a80d98d40b2bc9bdb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb6a865a8fd94ff2982a2d2533d3d9c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7ebc6e54f29b4a5d9aa4760b4bcd0e59",
       "IPY_MODEL_32c94d50cb2442068e753b205c17217e",
       "IPY_MODEL_00e977416cd945e980b3be1388e94010"
      ],
      "layout": "IPY_MODEL_b718655efcad480597c3406a54f40c22"
     }
    },
    "f18a6478826d43bc87ae379713baa239": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
